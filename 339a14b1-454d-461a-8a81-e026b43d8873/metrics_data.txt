{"339a14b1-454d-461a-8a81-e026b43d8873_0":{"AUC_micro":[0.979695082216353],"average_precision_score_weighted":[0.9531771295804466],"average_precision_score_micro":[0.9806603102489483],"average_precision_score_macro":[0.8151093723721079],"weighted_accuracy":[0.9514937218005303],"AUC_weighted":[0.9450464668693167],"precision_score_weighted":[0.9072720074188747],"f1_score_micro":[0.9116843702579667],"precision_score_macro":[0.7819118765348991],"precision_score_micro":[0.9116843702579667],"balanced_accuracy":[0.7513392683482543],"log_loss":[0.17775706110025447],"recall_score_macro":[0.7513392683482543],"norm_macro_recall":[0.5026785366965085],"recall_score_micro":[0.9116843702579667],"AUC_macro":[0.9450464668693166],"matthews_correlation":[0.5323740218566827],"recall_score_weighted":[0.9116843702579667],"f1_score_weighted":[0.9091539479147899],"f1_score_macro":[0.7653697272147331],"accuracy":[0.9116843702579667]},"339a14b1-454d-461a-8a81-e026b43d8873_5":{"f1_score_weighted":[0.8743443754960211],"average_precision_score_micro":[0.9665436617909865],"matthews_correlation":[0.3322199855100232],"AUC_weighted":[0.8872124879827061],"log_loss":[0.2545263804808162],"AUC_macro":[0.8872124879827061],"recall_score_micro":[0.9001517450682853],"recall_score_weighted":[0.9001517450682853],"AUC_micro":[0.9654176903894023],"precision_score_weighted":[0.8828911139239553],"f1_score_macro":[0.6253276056987407],"precision_score_macro":[0.7996167104597064],"recall_score_macro":[0.5920927596152243],"f1_score_micro":[0.9001517450682853],"balanced_accuracy":[0.5920927596152243],"weighted_accuracy":[0.9766344583017204],"average_precision_score_weighted":[0.9288578418359287],"average_precision_score_macro":[0.7373649133907649],"accuracy":[0.9001517450682853],"precision_score_micro":[0.9001517450682853],"norm_macro_recall":[0.18418551923044868]},"339a14b1-454d-461a-8a81-e026b43d8873_2":{"precision_score_macro":[0.661780441036398],"AUC_micro":[0.8829727296381835],"f1_score_weighted":[0.8405063146423462],"AUC_macro":[0.8972931219401052],"recall_score_macro":[0.8111640890844998],"average_precision_score_weighted":[0.9357344158837815],"f1_score_micro":[0.8118361153262519],"norm_macro_recall":[0.6223281781689995],"recall_score_micro":[0.8118361153262519],"weighted_accuracy":[0.8120029612640768],"average_precision_score_micro":[0.8650043117441906],"precision_score_micro":[0.8118361153262519],"matthews_correlation":[0.44873272029919736],"average_precision_score_macro":[0.7620662723354072],"recall_score_weighted":[0.8118361153262519],"accuracy":[0.8118361153262519],"precision_score_weighted":[0.902038649652025],"f1_score_macro":[0.6877777737022351],"AUC_weighted":[0.8972931219401051],"balanced_accuracy":[0.8111640890844998],"log_loss":[0.5126161901369071]},"339a14b1-454d-461a-8a81-e026b43d8873_3":{"average_precision_score_macro":[0.7105436265564933],"AUC_weighted":[0.8855296037581019],"average_precision_score_micro":[0.9650212300278675],"recall_score_macro":[0.5],"recall_score_weighted":[0.8880121396054628],"AUC_micro":[0.9646913403994188],"accuracy":[0.8880121396054628],"log_loss":[0.27423480293639574],"f1_score_macro":[0.4703423886834914],"average_precision_score_weighted":[0.9219133137572686],"recall_score_micro":[0.8880121396054628],"AUC_macro":[0.8855296037581019],"f1_score_weighted":[0.8353395018439429],"precision_score_weighted":[0.788565560086672],"weighted_accuracy":[0.9843450583187134],"norm_macro_recall":[0.0],"precision_score_macro":[0.4440060698027314],"precision_score_micro":[0.8880121396054628],"matthews_correlation":[0.0],"f1_score_micro":[0.8880121396054628],"balanced_accuracy":[0.5]},"339a14b1-454d-461a-8a81-e026b43d8873_1":{"log_loss":[0.2337427162337183],"recall_score_weighted":[0.8934749620637329],"recall_score_macro":[0.5291267711036646],"weighted_accuracy":[0.9839327624273123],"balanced_accuracy":[0.5291267711036646],"f1_score_micro":[0.8934749620637329],"norm_macro_recall":[0.058253542207329145],"precision_score_macro":[0.870002588418006],"precision_score_micro":[0.8934749620637329],"average_precision_score_weighted":[0.9379919602864641],"recall_score_micro":[0.8934749620637329],"AUC_micro":[0.9697881325685445],"f1_score_weighted":[0.8501732159699232],"AUC_macro":[0.9106941411177611],"precision_score_weighted":[0.8885097914436377],"average_precision_score_macro":[0.765407575496744],"average_precision_score_micro":[0.9710247082993022],"AUC_weighted":[0.910694141117761],"accuracy":[0.8934749620637329],"matthews_correlation":[0.20762447544174234],"f1_score_macro":[0.5273669047108224]},"339a14b1-454d-461a-8a81-e026b43d8873_4":{"weighted_accuracy":[0.9730611889183236],"f1_score_weighted":[0.8734704046383025],"precision_score_micro":[0.8977238239757208],"AUC_macro":[0.9038556294653856],"recall_score_macro":[0.5942781010175104],"matthews_correlation":[0.31999379338174755],"balanced_accuracy":[0.5942781010175104],"AUC_weighted":[0.9038556294653857],"f1_score_micro":[0.8977238239757208],"norm_macro_recall":[0.18855620203502088],"recall_score_weighted":[0.8977238239757208],"average_precision_score_macro":[0.7327060420978794],"precision_score_weighted":[0.877014103638037],"average_precision_score_weighted":[0.9299249023156757],"average_precision_score_micro":[0.9694621875491184],"accuracy":[0.8977238239757208],"f1_score_macro":[0.6263947343363969],"precision_score_macro":[0.771526544069397],"log_loss":[0.23174489450091904],"recall_score_micro":[0.8977238239757208],"AUC_micro":[0.9686851600691717]},"339a14b1-454d-461a-8a81-e026b43d8873_8":{"balanced_accuracy":[0.7233141982821059],"AUC_macro":[0.8218967596374529],"recall_score_macro":[0.7233141982821059],"matthews_correlation":[0.2972147676611311],"AUC_micro":[0.8198321363356905],"log_loss":[0.561672836167159],"precision_score_weighted":[0.8755209614579715],"f1_score_micro":[0.7125948406676783],"norm_macro_recall":[0.4466283965642117],"average_precision_score_macro":[0.7005274241447284],"f1_score_macro":[0.5895665553759242],"weighted_accuracy":[0.7099335141257332],"average_precision_score_weighted":[0.9099710365175449],"recall_score_weighted":[0.7125948406676783],"precision_score_macro":[0.5988927470749836],"recall_score_micro":[0.7125948406676783],"AUC_weighted":[0.8218967596374527],"precision_score_micro":[0.7125948406676783],"average_precision_score_micro":[0.7977558768441424],"f1_score_weighted":[0.7639475562024294],"accuracy":[0.7125948406676783]},"339a14b1-454d-461a-8a81-e026b43d8873_13":{"f1_score_micro":[0.8880121396054628],"average_precision_score_micro":[0.9659849341310023],"AUC_macro":[0.8913368046872541],"matthews_correlation":[0.0],"f1_score_macro":[0.4703423886834914],"norm_macro_recall":[0.0],"precision_score_weighted":[0.788565560086672],"average_precision_score_weighted":[0.9209455673241687],"AUC_weighted":[0.8913368046872541],"recall_score_macro":[0.5],"log_loss":[0.24416466797762368],"weighted_accuracy":[0.9843450583187134],"recall_score_weighted":[0.8880121396054628],"recall_score_micro":[0.8880121396054628],"precision_score_micro":[0.8880121396054628],"AUC_micro":[0.965846352937384],"balanced_accuracy":[0.5],"f1_score_weighted":[0.8353395018439429],"precision_score_macro":[0.4440060698027314],"accuracy":[0.8880121396054628],"average_precision_score_macro":[0.7002866389181523]},"339a14b1-454d-461a-8a81-e026b43d8873_12":{"AUC_micro":[0.9669008775424206],"balanced_accuracy":[0.5132083720016968],"average_precision_score_weighted":[0.9302953663416503],"norm_macro_recall":[0.026416744003393555],"log_loss":[0.24989012696132146],"recall_score_weighted":[0.8904400606980273],"f1_score_macro":[0.49717601534306527],"average_precision_score_macro":[0.7380289504151685],"f1_score_weighted":[0.8422604916548835],"AUC_weighted":[0.8965544867342045],"matthews_correlation":[0.13829407288677828],"precision_score_macro":[0.8619910650827496],"AUC_macro":[0.8965544867342043],"f1_score_micro":[0.8904400606980273],"weighted_accuracy":[0.9840964850568034],"accuracy":[0.8904400606980273],"precision_score_weighted":[0.8842301607074102],"precision_score_micro":[0.8904400606980273],"recall_score_macro":[0.5132083720016968],"average_precision_score_micro":[0.9681947862384859],"recall_score_micro":[0.8904400606980273]},"339a14b1-454d-461a-8a81-e026b43d8873_15":{"recall_score_weighted":[0.7377845220030349],"precision_score_weighted":[0.8787371844507742],"average_precision_score_weighted":[0.9112423113832518],"AUC_macro":[0.8217953420135705],"average_precision_score_micro":[0.7967626566530617],"f1_score_macro":[0.6094120436225701],"AUC_micro":[0.8201296395651663],"recall_score_macro":[0.7363132517176163],"f1_score_weighted":[0.7831804010703461],"average_precision_score_macro":[0.712092299832636],"recall_score_micro":[0.7377845220030349],"matthews_correlation":[0.3209349901039283],"f1_score_micro":[0.7377845220030349],"weighted_accuracy":[0.7381497986177166],"norm_macro_recall":[0.4726265034352326],"accuracy":[0.7377845220030349],"precision_score_macro":[0.6089647608887462],"AUC_weighted":[0.8217953420135704],"balanced_accuracy":[0.7363132517176163],"precision_score_micro":[0.7377845220030349],"log_loss":[0.5651993841518604]},"339a14b1-454d-461a-8a81-e026b43d8873_14":{"f1_score_micro":[0.723823975720789],"norm_macro_recall":[0.48058801845708143],"f1_score_macro":[0.601994824319962],"average_precision_score_micro":[0.7899473945066195],"precision_score_macro":[0.6073068803727062],"average_precision_score_weighted":[0.9170007101909153],"recall_score_weighted":[0.723823975720789],"f1_score_weighted":[0.7728764151767448],"average_precision_score_macro":[0.711194088577891],"AUC_macro":[0.8521243055902876],"weighted_accuracy":[0.7197349119076825],"AUC_micro":[0.8279653035707296],"log_loss":[0.5231591505452543],"AUC_weighted":[0.8521243055902875],"precision_score_micro":[0.723823975720789],"balanced_accuracy":[0.7402940092285407],"precision_score_weighted":[0.8808920160981865],"accuracy":[0.723823975720789],"matthews_correlation":[0.3211554172207902],"recall_score_macro":[0.7402940092285407],"recall_score_micro":[0.723823975720789]},"339a14b1-454d-461a-8a81-e026b43d8873_17":{"recall_score_weighted":[0.8971168437025797],"weighted_accuracy":[0.9832659146386543],"norm_macro_recall":[0.10024692181303219],"AUC_weighted":[0.9286853497379813],"f1_score_micro":[0.8971168437025797],"f1_score_weighted":[0.8597699719152083],"log_loss":[0.24081208153548977],"average_precision_score_micro":[0.9747150118552796],"precision_score_micro":[0.8971168437025797],"matthews_correlation":[0.26944344246438173],"AUC_macro":[0.9286853497379813],"f1_score_macro":[0.5641168723476904],"precision_score_macro":[0.8621047278761358],"balanced_accuracy":[0.5501234609065161],"AUC_micro":[0.9735451470361356],"average_precision_score_weighted":[0.9472148105076709],"average_precision_score_macro":[0.7971595506920505],"recall_score_micro":[0.8971168437025797],"recall_score_macro":[0.5501234609065161],"precision_score_weighted":[0.8900553929302153],"accuracy":[0.8971168437025797]},"339a14b1-454d-461a-8a81-e026b43d8873_16":{"AUC_macro":[0.8698302481999529],"norm_macro_recall":[0.49542833432435485],"balanced_accuracy":[0.7477141671621774],"recall_score_micro":[0.7496206373292867],"f1_score_weighted":[0.7923259769225286],"recall_score_weighted":[0.7496206373292867],"precision_score_weighted":[0.8821580454948101],"AUC_weighted":[0.8698302481999529],"average_precision_score_macro":[0.7305687992600725],"recall_score_macro":[0.7477141671621774],"accuracy":[0.7496206373292867],"f1_score_micro":[0.7496206373292867],"average_precision_score_micro":[0.8450059515501576],"precision_score_micro":[0.7496206373292867],"weighted_accuracy":[0.7500939623026347],"f1_score_macro":[0.6209012464046021],"average_precision_score_weighted":[0.9253410519242005],"precision_score_macro":[0.616146936641401],"log_loss":[0.555427421216463],"AUC_micro":[0.8491522309288224],"matthews_correlation":[0.33924175261051137]},"339a14b1-454d-461a-8a81-e026b43d8873_19":{"precision_score_weighted":[0.788565560086672],"average_precision_score_macro":[0.7764812188970184],"precision_score_macro":[0.4440060698027314],"f1_score_weighted":[0.8353395018439429],"recall_score_weighted":[0.8880121396054628],"recall_score_macro":[0.5],"f1_score_micro":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"AUC_micro":[0.9717767067866198],"f1_score_macro":[0.4703423886834914],"log_loss":[0.24067813828975793],"AUC_weighted":[0.9211535861086566],"recall_score_micro":[0.8880121396054628],"balanced_accuracy":[0.5],"norm_macro_recall":[0.0],"AUC_macro":[0.9211535861086568],"matthews_correlation":[0.0],"average_precision_score_weighted":[0.9412207262426506],"accuracy":[0.8880121396054628],"precision_score_micro":[0.8880121396054628],"average_precision_score_micro":[0.9722141051759806]},"339a14b1-454d-461a-8a81-e026b43d8873_25":{"average_precision_score_macro":[0.8071742282912644],"log_loss":[0.18438902755770786],"average_precision_score_weighted":[0.9509461669750866],"AUC_weighted":[0.9407813695361834],"accuracy":[0.9119878603945372],"precision_score_macro":[0.7854355288470023],"balanced_accuracy":[0.7396688320950195],"precision_score_micro":[0.9119878603945372],"recall_score_weighted":[0.9119878603945372],"recall_score_micro":[0.9119878603945372],"f1_score_weighted":[0.9081566096944386],"AUC_micro":[0.978414897266977],"weighted_accuracy":[0.9547700139704612],"f1_score_macro":[0.7597246696921418],"norm_macro_recall":[0.4793376641900391],"average_precision_score_micro":[0.9794493482917321],"precision_score_weighted":[0.9057755480984142],"f1_score_micro":[0.9119878603945372],"AUC_macro":[0.9407813695361835],"recall_score_macro":[0.7396688320950195],"matthews_correlation":[0.523106107160623]},"339a14b1-454d-461a-8a81-e026b43d8873_20":{"average_precision_score_micro":[0.9756497344937594],"f1_score_macro":[0.6136146528695394],"AUC_micro":[0.9744804861368561],"f1_score_weighted":[0.8719631449552753],"accuracy":[0.9004552352048558],"f1_score_micro":[0.9004552352048558],"log_loss":[0.22589233807484954],"average_precision_score_weighted":[0.945222197717833],"balanced_accuracy":[0.5827905869626023],"weighted_accuracy":[0.9793227746800656],"recall_score_weighted":[0.9004552352048558],"recall_score_micro":[0.9004552352048558],"matthews_correlation":[0.3256750549961802],"precision_score_weighted":[0.8859664258327548],"average_precision_score_macro":[0.787108791806625],"precision_score_macro":[0.8202786854702324],"norm_macro_recall":[0.16558117392520466],"recall_score_macro":[0.5827905869626023],"precision_score_micro":[0.9004552352048558],"AUC_weighted":[0.9304904908242522],"AUC_macro":[0.9304904908242521]},"339a14b1-454d-461a-8a81-e026b43d8873_23":{"accuracy":[0.8880121396054628],"f1_score_micro":[0.8880121396054628],"log_loss":[0.26008614822798515],"average_precision_score_micro":[0.9596430254834719],"matthews_correlation":[0.0],"precision_score_weighted":[0.788565560086672],"f1_score_weighted":[0.8353395018439429],"AUC_micro":[0.9588505138378146],"average_precision_score_macro":[0.6814824210729673],"recall_score_weighted":[0.8880121396054628],"recall_score_micro":[0.8880121396054628],"recall_score_macro":[0.5],"norm_macro_recall":[0.0],"average_precision_score_weighted":[0.9129287072160509],"precision_score_macro":[0.4440060698027314],"precision_score_micro":[0.8880121396054628],"f1_score_macro":[0.4703423886834914],"weighted_accuracy":[0.9843450583187134],"AUC_weighted":[0.8561629498728343],"balanced_accuracy":[0.5],"AUC_macro":[0.8561629498728344]},"339a14b1-454d-461a-8a81-e026b43d8873_24":{"precision_score_micro":[0.8937784522003035],"f1_score_macro":[0.5627216251550807],"recall_score_macro":[0.5494278934587021],"recall_score_weighted":[0.8937784522003035],"average_precision_score_micro":[0.9649052282878874],"f1_score_micro":[0.8937784522003035],"balanced_accuracy":[0.5494278934587021],"matthews_correlation":[0.23508351690271984],"AUC_weighted":[0.8920212578749165],"weighted_accuracy":[0.9792713814108361],"norm_macro_recall":[0.09885578691740426],"AUC_micro":[0.9660908950656372],"f1_score_weighted":[0.8579822832487796],"recall_score_micro":[0.8937784522003035],"precision_score_macro":[0.7795195994217594],"AUC_macro":[0.8920212578749165],"precision_score_weighted":[0.8714805331815131],"accuracy":[0.8937784522003035],"average_precision_score_weighted":[0.9241653599051056],"log_loss":[0.25745586598345016],"average_precision_score_macro":[0.7196699772981756]},"339a14b1-454d-461a-8a81-e026b43d8873_21":{"average_precision_score_micro":[0.9805426494262558],"matthews_correlation":[0.527343824348664],"norm_macro_recall":[0.48678421849153564],"AUC_macro":[0.9453011686644549],"AUC_micro":[0.9795946863896877],"precision_score_micro":[0.9122913505311078],"precision_score_weighted":[0.9065237929615331],"f1_score_macro":[0.7621206659537194],"balanced_accuracy":[0.7433921092457678],"recall_score_micro":[0.9122913505311078],"average_precision_score_weighted":[0.9531295963042634],"f1_score_weighted":[0.9087923391639493],"log_loss":[0.1794115673144867],"average_precision_score_macro":[0.8148761708639233],"accuracy":[0.9122913505311078],"recall_score_weighted":[0.9122913505311078],"weighted_accuracy":[0.954224463495085],"precision_score_macro":[0.7856414593106926],"recall_score_macro":[0.7433921092457678],"AUC_weighted":[0.9453011686644548],"f1_score_micro":[0.9122913505311078]},"339a14b1-454d-461a-8a81-e026b43d8873_27":{"average_precision_score_micro":[0.8083220111566742],"AUC_macro":[0.8574883253958993],"log_loss":[0.5030278501227111],"average_precision_score_macro":[0.6831276510208653],"recall_score_weighted":[0.6091047040971168],"precision_score_micro":[0.6091047040971168],"balanced_accuracy":[0.7645105928161127],"matthews_correlation":[0.3336720019300778],"recall_score_micro":[0.6091047040971168],"accuracy":[0.6091047040971168],"weighted_accuracy":[0.5705216255863518],"AUC_weighted":[0.8574883253958995],"f1_score_micro":[0.6091047040971168],"recall_score_macro":[0.7645105928161127],"precision_score_macro":[0.6052292496934396],"f1_score_weighted":[0.6786947120645594],"AUC_micro":[0.7761753334822384],"precision_score_weighted":[0.905518246972309],"average_precision_score_weighted":[0.9123000736555147],"norm_macro_recall":[0.5290211856322253],"f1_score_macro":[0.5376949891067537]},"339a14b1-454d-461a-8a81-e026b43d8873_26":{"AUC_weighted":[0.8310646349799111],"log_loss":[0.5119200052381704],"AUC_micro":[0.7555829520517823],"precision_score_macro":[0.5976389023271582],"f1_score_macro":[0.49187516213460314],"AUC_macro":[0.831064634979911],"average_precision_score_weighted":[0.8993508000227649],"precision_score_weighted":[0.9087947749727943],"f1_score_weighted":[0.6187268294234901],"weighted_accuracy":[0.4956317445761418],"f1_score_micro":[0.5444613050075873],"accuracy":[0.5444613050075873],"average_precision_score_macro":[0.6465850581346401],"matthews_correlation":[0.3068841610583649],"recall_score_macro":[0.7411382299058807],"norm_macro_recall":[0.4822764598117615],"recall_score_weighted":[0.5444613050075873],"average_precision_score_micro":[0.7958922406208293],"balanced_accuracy":[0.7411382299058807],"recall_score_micro":[0.5444613050075873],"precision_score_micro":[0.5444613050075873]},"339a14b1-454d-461a-8a81-e026b43d8873_33":{"AUC_macro":[0.9281514021565369],"log_loss":[0.2089029499976087],"precision_score_micro":[0.9101669195751139],"average_precision_score_macro":[0.7917627485118555],"norm_macro_recall":[0.330454739954098],"precision_score_macro":[0.8100634396454331],"recall_score_weighted":[0.9101669195751139],"recall_score_micro":[0.9101669195751139],"f1_score_micro":[0.9101669195751139],"f1_score_macro":[0.7083324361891228],"average_precision_score_micro":[0.9762909783195098],"balanced_accuracy":[0.665227369977049],"recall_score_macro":[0.665227369977049],"matthews_correlation":[0.4526851738621552],"accuracy":[0.9101669195751139],"f1_score_weighted":[0.8966180159111143],"weighted_accuracy":[0.9709787842376039],"AUC_micro":[0.9752979292209423],"AUC_weighted":[0.9281514021565367],"precision_score_weighted":[0.897572703980542],"average_precision_score_weighted":[0.9459832186516041]},"339a14b1-454d-461a-8a81-e026b43d8873_18":{"f1_score_weighted":[0.9086613440609772],"norm_macro_recall":[0.4800211911893555],"precision_score_micro":[0.9125948406676783],"accuracy":[0.9125948406676783],"matthews_correlation":[0.5254139610791995],"AUC_macro":[0.943998021661693],"recall_score_macro":[0.7400105955946777],"log_loss":[0.17981385781039308],"weighted_accuracy":[0.9554428403944659],"AUC_weighted":[0.943998021661693],"recall_score_micro":[0.9125948406676783],"AUC_micro":[0.9792565642982309],"precision_score_macro":[0.78754962860383],"average_precision_score_weighted":[0.9525161907226625],"recall_score_weighted":[0.9125948406676783],"f1_score_micro":[0.9125948406676783],"average_precision_score_macro":[0.8126929119384294],"balanced_accuracy":[0.7400105955946777],"average_precision_score_micro":[0.9802395848606664],"f1_score_macro":[0.7607503025413473],"precision_score_weighted":[0.9062798949414683]},"339a14b1-454d-461a-8a81-e026b43d8873_31":{"balanced_accuracy":[0.743733872745426],"average_precision_score_weighted":[0.9517838306968476],"f1_score_weighted":[0.9092974412848348],"AUC_micro":[0.9788862050147255],"accuracy":[0.9128983308042489],"precision_score_macro":[0.7877194593684469],"precision_score_micro":[0.9128983308042489],"AUC_weighted":[0.9424920394111663],"precision_score_weighted":[0.907019636133764],"average_precision_score_macro":[0.8101845152999028],"f1_score_micro":[0.9128983308042489],"matthews_correlation":[0.5296299768558868],"recall_score_micro":[0.9128983308042489],"AUC_macro":[0.9424920394111664],"log_loss":[0.1816076074356531],"norm_macro_recall":[0.48746774549085203],"recall_score_macro":[0.743733872745426],"recall_score_weighted":[0.9128983308042489],"average_precision_score_micro":[0.9798810767294689],"f1_score_macro":[0.7631470523778217],"weighted_accuracy":[0.9548972899190897]},"339a14b1-454d-461a-8a81-e026b43d8873_36":{"f1_score_micro":[0.9083459787556905],"accuracy":[0.9083459787556905],"average_precision_score_micro":[0.977152754319198],"f1_score_weighted":[0.9025288323944487],"precision_score_macro":[0.7778318057957909],"recall_score_weighted":[0.9083459787556905],"weighted_accuracy":[0.9563188254464977],"recall_score_macro":[0.7151197468912488],"AUC_weighted":[0.9312457974203802],"f1_score_macro":[0.7408501014629837],"norm_macro_recall":[0.4302394937824976],"average_precision_score_weighted":[0.9468497812913245],"matthews_correlation":[0.488946245475427],"recall_score_micro":[0.9083459787556905],"average_precision_score_macro":[0.7936798618838719],"AUC_micro":[0.9760318319244913],"precision_score_micro":[0.9083459787556905],"AUC_macro":[0.9312457974203802],"precision_score_weighted":[0.8995847208846137],"log_loss":[0.19708712990741808],"balanced_accuracy":[0.7151197468912488]},"339a14b1-454d-461a-8a81-e026b43d8873_38":{"precision_score_micro":[0.9053110773899848],"AUC_micro":[0.9763752961792019],"AUC_macro":[0.9342526678855305],"average_precision_score_weighted":[0.9484874787008328],"balanced_accuracy":[0.628153439770898],"f1_score_weighted":[0.8861733588164185],"precision_score_weighted":[0.8905400287071871],"AUC_weighted":[0.9342526678855304],"f1_score_micro":[0.9053110773899848],"norm_macro_recall":[0.256306879541796],"log_loss":[0.20981680406070358],"precision_score_macro":[0.8069790298533953],"average_precision_score_micro":[0.9774270588941639],"recall_score_micro":[0.9053110773899848],"average_precision_score_macro":[0.7998616245795696],"accuracy":[0.9053110773899848],"matthews_correlation":[0.3966883845702862],"f1_score_macro":[0.6696461623889437],"recall_score_macro":[0.628153439770898],"weighted_accuracy":[0.9741218218235597],"recall_score_weighted":[0.9053110773899848]},"339a14b1-454d-461a-8a81-e026b43d8873_40":{"average_precision_score_weighted":[0.9548071164583597],"balanced_accuracy":[0.707355509987089],"AUC_macro":[0.9462431022122935],"f1_score_weighted":[0.9038235706737056],"precision_score_micro":[0.9113808801213961],"precision_score_macro":[0.7930204281428819],"accuracy":[0.9113808801213961],"f1_score_micro":[0.9113808801213961],"recall_score_macro":[0.707355509987089],"norm_macro_recall":[0.4147110199741779],"AUC_micro":[0.9800599151240785],"f1_score_macro":[0.7400605176419732],"AUC_weighted":[0.9462431022122935],"average_precision_score_macro":[0.8219570530206379],"precision_score_weighted":[0.901379782138249],"weighted_accuracy":[0.9620348607328634],"matthews_correlation":[0.4929884392729809],"average_precision_score_micro":[0.9809874331335338],"recall_score_micro":[0.9113808801213961],"log_loss":[0.18231759588796836],"recall_score_weighted":[0.9113808801213961]},"339a14b1-454d-461a-8a81-e026b43d8873_28":{"precision_score_micro":[0.9001517450682853],"AUC_weighted":[0.9201264432329901],"recall_score_macro":[0.6595882722326882],"precision_score_weighted":[0.8850169701264143],"precision_score_macro":[0.7568725346086531],"AUC_macro":[0.9201264432329901],"recall_score_micro":[0.9001517450682853],"norm_macro_recall":[0.31917654446537647],"average_precision_score_weighted":[0.9381636135454935],"matthews_correlation":[0.4049387310802776],"f1_score_micro":[0.9001517450682853],"average_precision_score_macro":[0.7617064290625448],"log_loss":[0.2263503732293119],"AUC_micro":[0.9696464731360571],"f1_score_weighted":[0.8885650482895828],"f1_score_macro":[0.6923585339641367],"recall_score_weighted":[0.9001517450682853],"weighted_accuracy":[0.9598771482415283],"balanced_accuracy":[0.6595882722326882],"accuracy":[0.9001517450682853],"average_precision_score_micro":[0.9676100200686012]},"339a14b1-454d-461a-8a81-e026b43d8873_41":{"recall_score_micro":[0.9138088012139606],"precision_score_weighted":[0.9043313508650864],"accuracy":[0.9138088012139606],"norm_macro_recall":[0.4269181823738948],"average_precision_score_micro":[0.9807758420387869],"weighted_accuracy":[0.9635502148457104],"AUC_macro":[0.9454382445396565],"f1_score_weighted":[0.9064585413401792],"f1_score_micro":[0.9138088012139606],"log_loss":[0.20080796716932786],"average_precision_score_weighted":[0.954265625846417],"f1_score_macro":[0.7471821472956177],"balanced_accuracy":[0.7134590911869474],"recall_score_weighted":[0.9138088012139606],"matthews_correlation":[0.5074997246006845],"AUC_micro":[0.9798442022561429],"average_precision_score_macro":[0.8199626135583138],"precision_score_micro":[0.9138088012139606],"recall_score_macro":[0.7134590911869474],"precision_score_macro":[0.8016455858563118],"AUC_weighted":[0.9454382445396566]},"339a14b1-454d-461a-8a81-e026b43d8873_34":{"norm_macro_recall":[0.4343165748814015],"accuracy":[0.9098634294385433],"log_loss":[0.18275234244638672],"AUC_micro":[0.9792894462341204],"matthews_correlation":[0.4960278986024002],"balanced_accuracy":[0.7171582874407008],"precision_score_micro":[0.9098634294385433],"precision_score_macro":[0.7832538411170469],"average_precision_score_macro":[0.8157252549391669],"average_precision_score_micro":[0.9802711780964346],"precision_score_weighted":[0.9011063046547484],"recall_score_micro":[0.9098634294385433],"recall_score_macro":[0.7171582874407008],"AUC_weighted":[0.9434487919725404],"f1_score_macro":[0.7440807485301082],"f1_score_micro":[0.9098634294385431],"recall_score_weighted":[0.9098634294385433],"AUC_macro":[0.9434487919725404],"f1_score_weighted":[0.9039247587423512],"weighted_accuracy":[0.9577069036107164],"average_precision_score_weighted":[0.9531335170004281]},"339a14b1-454d-461a-8a81-e026b43d8873_6":{"f1_score_micro":[0.8910470409711685],"matthews_correlation":[0.1543521188653006],"AUC_micro":[0.9575298942389836],"log_loss":[0.2762208041650092],"accuracy":[0.8910470409711685],"precision_score_macro":[0.8741672834937083],"f1_score_macro":[0.5024126302275582],"average_precision_score_macro":[0.7223872437653129],"balanced_accuracy":[0.5159183991019678],"f1_score_weighted":[0.8436688761998834],"recall_score_weighted":[0.8910470409711685],"recall_score_micro":[0.8910470409711685],"precision_score_micro":[0.8910470409711685],"average_precision_score_weighted":[0.9195252758413118],"norm_macro_recall":[0.03183679820393559],"weighted_accuracy":[0.9841813356892222],"precision_score_weighted":[0.8873786516816071],"average_precision_score_micro":[0.9574926859968602],"AUC_macro":[0.849298041852599],"AUC_weighted":[0.8492980418525989],"recall_score_macro":[0.5159183991019678]},"339a14b1-454d-461a-8a81-e026b43d8873_29":{"average_precision_score_macro":[0.7387745209553365],"recall_score_macro":[0.5],"log_loss":[0.23335663880415466],"f1_score_weighted":[0.8353395018439429],"accuracy":[0.8880121396054628],"AUC_weighted":[0.9036509418409289],"AUC_macro":[0.9036509418409291],"average_precision_score_micro":[0.9696066318198451],"weighted_accuracy":[0.9843450583187134],"recall_score_weighted":[0.8880121396054628],"average_precision_score_weighted":[0.9314415542832822],"matthews_correlation":[0.0],"precision_score_macro":[0.4440060698027314],"recall_score_micro":[0.8880121396054628],"precision_score_micro":[0.8880121396054628],"balanced_accuracy":[0.5],"f1_score_macro":[0.4703423886834914],"f1_score_micro":[0.8880121396054628],"AUC_micro":[0.9682955505767004],"norm_macro_recall":[0.0],"precision_score_weighted":[0.788565560086672]},"339a14b1-454d-461a-8a81-e026b43d8873_35":{"recall_score_micro":[0.9062215477996965],"recall_score_weighted":[0.9062215477996965],"average_precision_score_micro":[0.9767467212276617],"balanced_accuracy":[0.6665583026301897],"AUC_weighted":[0.931688052355575],"precision_score_micro":[0.9062215477996965],"AUC_micro":[0.9755748006475069],"AUC_macro":[0.9316880523555748],"accuracy":[0.9062215477996965],"average_precision_score_macro":[0.7803339628006043],"weighted_accuracy":[0.9657234487941955],"f1_score_macro":[0.7046892443486908],"matthews_correlation":[0.43589515291115394],"recall_score_macro":[0.6665583026301897],"average_precision_score_weighted":[0.9439496380595473],"f1_score_micro":[0.9062215477996965],"precision_score_weighted":[0.8923872386749484],"norm_macro_recall":[0.33311660526037934],"log_loss":[0.20365945063058502],"precision_score_macro":[0.7851923040325803],"f1_score_weighted":[0.8940052252172512]},"339a14b1-454d-461a-8a81-e026b43d8873_22":{"average_precision_score_micro":[0.9777871805237555],"weighted_accuracy":[0.9609831957806473],"recall_score_weighted":[0.9101669195751139],"balanced_accuracy":[0.705487851187466],"f1_score_micro":[0.9101669195751139],"matthews_correlation":[0.4867731611986173],"precision_score_macro":[0.7882750842617063],"AUC_macro":[0.9342679499932389],"recall_score_micro":[0.9101669195751139],"f1_score_weighted":[0.9026632441364442],"log_loss":[0.1921852994995217],"recall_score_macro":[0.705487851187466],"AUC_weighted":[0.9342679499932388],"average_precision_score_macro":[0.7998321444303222],"average_precision_score_weighted":[0.9486146431518476],"AUC_micro":[0.9766515228619257],"accuracy":[0.9101669195751139],"precision_score_weighted":[0.9000274768383943],"norm_macro_recall":[0.4109757023749321],"precision_score_micro":[0.9101669195751139],"f1_score_macro":[0.7372589501995638]},"339a14b1-454d-461a-8a81-e026b43d8873_32":{"matthews_correlation":[0.0],"f1_score_weighted":[0.8353395018439429],"AUC_micro":[0.9744062484888817],"recall_score_weighted":[0.8880121396054628],"precision_score_macro":[0.4440060698027314],"average_precision_score_micro":[0.9755997293287618],"AUC_macro":[0.9343744616530238],"log_loss":[0.29313359336803707],"precision_score_weighted":[0.788565560086672],"AUC_weighted":[0.934374461653024],"f1_score_micro":[0.8880121396054628],"average_precision_score_macro":[0.8004617629290862],"precision_score_micro":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"f1_score_macro":[0.4703423886834914],"recall_score_macro":[0.5],"balanced_accuracy":[0.5],"recall_score_micro":[0.8880121396054628],"accuracy":[0.8880121396054628],"average_precision_score_weighted":[0.948588659974036],"norm_macro_recall":[0.0]},"339a14b1-454d-461a-8a81-e026b43d8873_37":{"average_precision_score_weighted":[0.9465656622314611],"AUC_macro":[0.9305405049949338],"f1_score_weighted":[0.8840916669567737],"f1_score_micro":[0.9053110773899848],"accuracy":[0.9053110773899848],"precision_score_weighted":[0.891492202985249],"weighted_accuracy":[0.9764737249899024],"average_precision_score_micro":[0.9765077259731114],"AUC_micro":[0.9753812853889532],"balanced_accuracy":[0.6186803853684469],"recall_score_macro":[0.6186803853684469],"average_precision_score_macro":[0.7929788292971939],"precision_score_micro":[0.9053110773899848],"f1_score_macro":[0.6598849211810665],"recall_score_weighted":[0.9053110773899848],"AUC_weighted":[0.9305405049949337],"log_loss":[0.216948967296587],"norm_macro_recall":[0.23736077073689388],"matthews_correlation":[0.3888345439366291],"precision_score_macro":[0.8184862900660145],"recall_score_micro":[0.9053110773899848]},"339a14b1-454d-461a-8a81-e026b43d8873_9":{"balanced_accuracy":[0.7683473280392408],"log_loss":[0.5106366413934654],"accuracy":[0.7189681335356601],"precision_score_micro":[0.7189681335356601],"AUC_macro":[0.8678579301172369],"matthews_correlation":[0.3536078610400391],"average_precision_score_macro":[0.7217243414702912],"recall_score_macro":[0.7683473280392408],"AUC_micro":[0.8430627174571304],"weighted_accuracy":[0.7067086152250318],"precision_score_weighted":[0.8914506363239103],"recall_score_weighted":[0.7189681335356601],"f1_score_weighted":[0.7698303120578697],"average_precision_score_micro":[0.8236579584120403],"recall_score_micro":[0.7189681335356601],"precision_score_macro":[0.6164894395473793],"average_precision_score_weighted":[0.9232754959383448],"f1_score_micro":[0.7189681335356602],"f1_score_macro":[0.6076674810338176],"AUC_weighted":[0.8678579301172368],"norm_macro_recall":[0.5366946560784815]},"339a14b1-454d-461a-8a81-e026b43d8873_7":{"recall_score_micro":[0.8880121396054628],"AUC_micro":[0.9669939048680464],"recall_score_weighted":[0.8880121396054628],"norm_macro_recall":[0.0],"AUC_macro":[0.8971064949883949],"balanced_accuracy":[0.5],"precision_score_macro":[0.4440060698027314],"weighted_accuracy":[0.9843450583187134],"matthews_correlation":[0.0],"f1_score_micro":[0.8880121396054628],"log_loss":[0.2635543779672214],"f1_score_weighted":[0.8353395018439429],"average_precision_score_micro":[0.9679229606153467],"average_precision_score_macro":[0.7344526728065928],"precision_score_micro":[0.8880121396054628],"f1_score_macro":[0.4703423886834914],"precision_score_weighted":[0.788565560086672],"AUC_weighted":[0.897106494988395],"recall_score_macro":[0.5],"accuracy":[0.8880121396054628],"average_precision_score_weighted":[0.9291806070067037]},"339a14b1-454d-461a-8a81-e026b43d8873_10":{"f1_score_macro":[0.5906189435197944],"matthews_correlation":[0.37224849798494875],"AUC_micro":[0.831172996285815],"AUC_weighted":[0.8644384427439628],"precision_score_micro":[0.6828528072837633],"balanced_accuracy":[0.7906411446206054],"precision_score_macro":[0.6191924705231724],"f1_score_micro":[0.6828528072837633],"recall_score_weighted":[0.6828528072837633],"accuracy":[0.6828528072837633],"average_precision_score_macro":[0.7076510932964516],"average_precision_score_weighted":[0.9199901052907633],"AUC_macro":[0.8644384427439626],"recall_score_macro":[0.7906411446206054],"recall_score_micro":[0.6828528072837633],"average_precision_score_micro":[0.8500423917091432],"precision_score_weighted":[0.9042703708678851],"norm_macro_recall":[0.5812822892412108],"f1_score_weighted":[0.7414130545456694],"log_loss":[0.5138686070084797],"weighted_accuracy":[0.6560918787482164]},"339a14b1-454d-461a-8a81-e026b43d8873_11":{"accuracy":[0.7317147192716237],"precision_score_weighted":[0.881162982223747],"precision_score_micro":[0.7317147192716237],"AUC_micro":[0.8411110778505162],"f1_score_micro":[0.7317147192716237],"log_loss":[0.5808099690593631],"average_precision_score_weighted":[0.9215325697171075],"matthews_correlation":[0.3262007333214145],"AUC_macro":[0.863370084486901],"recall_score_weighted":[0.7317147192716237],"norm_macro_recall":[0.48473734224696985],"average_precision_score_macro":[0.7183289523494315],"f1_score_macro":[0.6076226901469619],"average_precision_score_micro":[0.827317559455218],"recall_score_micro":[0.7317147192716237],"precision_score_macro":[0.6097572944619718],"balanced_accuracy":[0.7423686711234849],"AUC_weighted":[0.863370084486901],"recall_score_macro":[0.7423686711234849],"weighted_accuracy":[0.7290696312113278],"f1_score_weighted":[0.7788603147944307]},"339a14b1-454d-461a-8a81-e026b43d8873_30":{"average_precision_score_weighted":[0.943523946918008],"log_loss":[0.31136044745279967],"f1_score_micro":[0.8880121396054628],"precision_score_weighted":[0.788565560086672],"recall_score_macro":[0.5],"f1_score_weighted":[0.8353395018439429],"average_precision_score_micro":[0.9736443067968061],"recall_score_weighted":[0.8880121396054628],"precision_score_micro":[0.8880121396054628],"accuracy":[0.8880121396054628],"precision_score_macro":[0.4440060698027314],"balanced_accuracy":[0.5],"average_precision_score_macro":[0.7825761605827746],"AUC_macro":[0.9249930998968227],"recall_score_micro":[0.8880121396054628],"matthews_correlation":[0.0],"f1_score_macro":[0.4703423886834914],"AUC_weighted":[0.9249930998968227],"weighted_accuracy":[0.9843450583187134],"norm_macro_recall":[0.0],"AUC_micro":[0.9725403598131164]}}